{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ],
   "id": "b26dfaea87e5355b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# BASSE dataset\n",
    "\n",
    "Procesa un archivo JSONL de resúmenes y devuelve una lista de objetos (diccionarios).\n",
    "Cada objeto contiene el índice, el documento original y los resúmenes de varios modelos.\n",
    "Además, se puede convertir la lista de objetos en un DataFrame de Pandas para un análisis más fácil."
   ],
   "id": "5175aec88b02454c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_list_of_objects_from_basse_dataset(filepath):\n",
    "    \"\"\"\n",
    "    Procesa un archivo JSONL de resúmenes y devuelve una lista de objetos (diccionarios).\n",
    "\n",
    "    Args:\n",
    "        filepath (str): La ruta al archivo .jsonl.\n",
    "\n",
    "    Returns:\n",
    "        list: Una lista de diccionarios, donde cada diccionario representa un objeto JSON procesado.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line_number, line in enumerate(f, 1):\n",
    "            try:\n",
    "                json_object = json.loads(line.strip())\n",
    "\n",
    "                idx = json_object.get('idx')\n",
    "                round_val = json_object.get('round')\n",
    "                original_document = json_object.get('original_document')\n",
    "\n",
    "                model_summaries = json_object.get('model_summaries', {})\n",
    "\n",
    "                claude_summ = model_summaries.get('claude-5w1h', {}).get('summ')\n",
    "                commandr_summ = model_summaries.get('commandr-5w1h', {}).get('summ')\n",
    "                gpt4o_summ = model_summaries.get('gpt4o-5w1h', {}).get('summ')\n",
    "                reka_summ = model_summaries.get('reka-5w1h', {}).get('summ')\n",
    "                llama3_summ = model_summaries.get('llama3-5w1h', {}).get('summ')\n",
    "\n",
    "                data_list.append({\n",
    "                    'idx': idx,\n",
    "                    'round': round_val,\n",
    "                    'original_document': original_document,\n",
    "                    'claude-5w1h_summ': claude_summ,\n",
    "                    'commandr-5w1h_summ': commandr_summ,\n",
    "                    'gpt4o-5w1h_summ': gpt4o_summ,\n",
    "                    'reka-5w1h_summ': reka_summ,\n",
    "                    'llama3-5w1h_summ': llama3_summ\n",
    "                })\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Advertencia (Línea {line_number}): Se omitió una línea (resúmenes) debido a un error de decodificación JSON: {line.strip()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Advertencia (Línea {line_number}): Se omitió una línea (resúmenes) debido a un error inesperado ({e}): {line.strip()}\")\n",
    "\n",
    "    return data_list"
   ],
   "id": "27d53d9a97d1a1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Procesar el archivo JSONL de resúmenes y generar una lista de diccionarios.\n",
   "id": "7e19aeb69795b99e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Procesar el archivo JSONL de resúmenes\n",
    "jsonl_file_path_summaries = 'data/basse/BASSE.jsonl'\n",
    "list_of_summary_objects = get_list_of_objects_from_basse_dataset(jsonl_file_path_summaries)\n",
    "\n",
    "# Ahora 'list_of_summary_objects' es una lista de diccionarios.\n",
    "if list_of_summary_objects:\n",
    "    print(\"Primer objeto de la lista de resúmenes:\")\n",
    "    print(json.dumps(list_of_summary_objects[0], indent=2, ensure_ascii=False))"
   ],
   "id": "62a1af22d9773e00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convertir la lista de diccionarios en un DataFrame de Pandas (opcional)",
   "id": "1f4c1434acd78210"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Para convertir la lista de diccionarios en un DataFrame de Pandas:\n",
    "df_summaries = pd.DataFrame(list_of_summary_objects)\n",
    "print(\"\\nDataFrame creado desde la lista de resúmenes:\")\n",
    "df_summaries"
   ],
   "id": "7254ab8e63f67d27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Flares dataset\n",
    "Similar al anterior, pero para un archivo JSON que contiene una lista de objetos, cada uno con un id, text, y una lista de tags.\n",
    "Cada tag tiene un campo '5W1H_Label', 'Reliability_Label' y 'Tag_Text'."
   ],
   "id": "99702bb49e840cd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_single_object_tags_nested(json_object):\n",
    "    \"\"\"\n",
    "    Procesa un único objeto JSON y anida las etiquetas procesadas (con enumeración)\n",
    "    dentro de una lista en el objeto resultante.\n",
    "    \"\"\"\n",
    "    processed_object = {\n",
    "        'Id': json_object.get('Id'),\n",
    "        'Text': json_object.get('Text'),\n",
    "        'Processed_Tags': [] # Lista para las etiquetas procesadas\n",
    "    }\n",
    "\n",
    "    tags = json_object.get('Tags', [])\n",
    "    w5h1_label_counts = defaultdict(int) # Contador para enumerar\n",
    "\n",
    "    if tags:\n",
    "        for tag_item in tags:\n",
    "            original_w5h1_label = tag_item.get('5W1H_Label')\n",
    "            reliability_label = tag_item.get('Reliability_Label')\n",
    "            tag_text = tag_item.get('Tag_Text')\n",
    "\n",
    "            enumerated_tag_id = None\n",
    "            if original_w5h1_label:\n",
    "                w5h1_label_counts[original_w5h1_label] += 1\n",
    "                current_count = w5h1_label_counts[original_w5h1_label]\n",
    "                enumerated_tag_id = f\"{original_w5h1_label}_{current_count}\"\n",
    "\n",
    "            processed_object['Processed_Tags'].append({\n",
    "                'Original_5W1H_Label': original_w5h1_label, # Mantenemos la original\n",
    "                'Enumerated_Tag_Id': enumerated_tag_id, # Ej: WHO_1, WHAT_2\n",
    "                'Reliability_Label': reliability_label,\n",
    "                'Tag_Text': tag_text\n",
    "            })\n",
    "\n",
    "    return processed_object\n",
    "\n",
    "def get_list_of_objects_from_tags_jsonl_nested(filepath):\n",
    "    \"\"\"\n",
    "    Procesa un archivo JSONL (con estructura de Tags) y devuelve una lista de objetos,\n",
    "    donde cada objeto contiene sus etiquetas procesadas de forma anidada.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): La ruta al archivo .jsonl.\n",
    "\n",
    "    Returns:\n",
    "        list: Una lista de diccionarios.\n",
    "    \"\"\"\n",
    "    all_processed_objects = []\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line_number, line in enumerate(f, 1):\n",
    "            try:\n",
    "                json_object = json.loads(line.strip())\n",
    "                processed_data = process_single_object_tags_nested(json_object)\n",
    "                all_processed_objects.append(processed_data)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Advertencia (Línea {line_number}): Se omitió una línea (etiquetas) debido a un error de decodificación JSON: {line.strip()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Advertencia (Línea {line_number}): Se omitió una línea (etiquetas) debido a un error inesperado ({e}): {line.strip()}\")\n",
    "\n",
    "    return all_processed_objects"
   ],
   "id": "840cdcb565830305",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Procesar el archivo JSONL de etiquetas y generar una lista de diccionarios.",
   "id": "e7702d99e4c8d1be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "jsonl_file_path_tags_nested = 'data/flares/5w1h_subtask_1_trial.json'\n",
    "list_of_tagged_objects_nested = get_list_of_objects_from_tags_jsonl_nested(jsonl_file_path_tags_nested)\n",
    "\n",
    "# Ahora 'list_of_tagged_objects_nested' es una lista de diccionarios,\n",
    "# y cada diccionario tiene una clave 'Processed_Tags' con una lista de etiquetas.\n",
    "if list_of_tagged_objects_nested:\n",
    "    print(\"Primer objeto de la lista de etiquetas (estructura anidada):\")\n",
    "    print(json.dumps(list_of_tagged_objects_nested[0], indent=2, ensure_ascii=False))"
   ],
   "id": "236cd2ff478c6dd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para crear un DataFrame principal (las etiquetas estarán como listas en una columna):",
   "id": "47ef584540cc5980"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_tags_main = pd.DataFrame(list_of_tagged_objects_nested)\n",
    "print(\"\\nDataFrame principal creado desde la lista de etiquetas (anidado):\")\n",
    "df_tags_main"
   ],
   "id": "1d7b8b7060431c2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para \"desanidar\" las etiquetas en filas separadas (formato largo):\n",
   "id": "eb8c4c5afe0c6e71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not df_tags_main.empty and 'Processed_Tags' in df_tags_main.columns:\n",
    "    df_tags_exploded = df_tags_main.explode('Processed_Tags')\n",
    "      # Normalizar la columna que ahora contiene diccionarios de etiquetas\n",
    "    df_tags_normalized = pd.json_normalize(df_tags_exploded['Processed_Tags'])\n",
    "      # Unir con las columnas originales (Id, Text) del DataFrame explotado\n",
    "    df_tags_final_long = pd.concat(\n",
    "        [df_tags_exploded[['Id', 'Text']].reset_index(drop=True), df_tags_normalized.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "print(\"\\nDataFrame en formato largo (cada etiqueta es una fila):\")\n",
    "df_tags_final_long"
   ],
   "id": "8eaf35ceaf94f17c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
